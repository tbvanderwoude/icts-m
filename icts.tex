\documentclass[a4paper,10pt,english]{article}
\usepackage[T1]{fontenc}
\usepackage{marginnote}
\include{prelude}
\usepackage{geometry}
\geometry{verbose,tmargin=3cm,bmargin=3cm,lmargin=3cm,rmargin=3cm}
\usepackage[backend=biber]{biblatex}
\addbibresource{sources.bib}
\usepackage{babel}


\title{Reviewed: The Increasing Cost Tree Search for Optimal Multi-agent Pathfinding}
\author{Thom van der Woude}
\date{\today}

\begin{document}
	\maketitle
	\paragraph{Overview}\marginnote{51 pages to go!}
	Typical optimal MAPF approach uses A* as single-agent search subroutine in finding per-agent paths. ICTS is a novel two-level method: top-level is an abstract increasing cost tree where each leaf represents a node where one agent gets a higher cost for its path (not a budget, exact cost!). The root node has a cost vector with the cost of the single-agent shortest path for each agent to target. What is the second-level processing of each node? It considers all combinations of all paths with the exact given cost per agent and sees if any has a non-conflicting solution. A smart datastructure is used to be able to enumerate all paths for a given agent.
	\paragraph{Solving MAPF: A* as a classical coupled approach}
    A* is a building block of MAPF algorithms: single-agent pathfinding can be done using A* and a proper heuristic $h(n)$ (remembering that $f(n) = g(n) + h(n)$), but multi-agent pathfinding can be reformulated as a 'single-agent' problem too: consider the state of this superagent to be the vector of all agent locations, and you can simply use A*. Specifically, each agent has at most $b$ + 1 actions where $b$ is the max degree of any location vertex and the $+1$ represents a wait action; for $k$ agents each $k$-agent state on the graph therefore has $O(b^k) \equiv O(e^k)$ children. It is clear that perhaps by using a good heuristic and given a lot of time and compute, A* can be used to solve MAPF. This is a traditional example of a coupled approach to MAPF, where the actions of all are coupled into one path-finding 'agent'. Decoupled approaches also exist but usually do not guarantee global optimality.
    
    When are coupled, decoupled approaches used? First for optimal solutions with lower $k$, second with suboptimal solutions with high $k$.
    
    Where is ICTS coming from? Complete MAPF solutions consist of individual paths of different agents. Let the increasing cost tree (ICT) consist of nodes represented by $k$-vectors $(C_1,C_2,\ldots,C_k)$ that represent all possible solutions in which the cost of each $\pi_i$ for agent $i$ is exactly $C_i$. The children of each node are all $k$-vectors generated by incrementing one of the costs. So an ICT node (with $k = 3$) $(4,3,5)$ may have three parents $(3,3,5),(4,2,5),(4,3,4)$ in a given instance (this is accounted for in implementation). Traversal is breadth-first. 
    
    The low-level routine searches the space of possible solutions with the costs as given by the node, which is done using multi-value decision diagrams which store all possible paths for a given cost and a given agent. All possible combinations of single-agent paths are considered to see if any non-conflicting combination exists.
    
    What is lost? Information from an admissible heuristic as in A*. There are pruning techniques however for recognizing nodes with no valid solution (look at pairs/triples(/quadruples/quintuples/...) of agents, see if there is any non-conflicting solution).
    
    There is both a theoretical and experimental comparison of ICTS and A*, with a naturel ICTS variant and a triple-pruning variant.
    \paragraph{n'th statement of MAPF and assumptions}
    $k$ agents $a_1,a_2,\ldots,a_k$. A graph $G = (V,E)$ with $|V| = N$. A $start_i,goal_i\in V$ for each agent $a_i$. $b_{base}$ is the (maximal) branching factor of a single-agent, so $b_{base} = 4+1$ in a 4-connected grid. Each action is assumed to have unit cost. Agents wait at goals (so they stay there and occupy it) but this costs nothing. Constraints: states can be occupied by at most one. Swapping is also illegal, but following is allowed. Sum of costs is minimized in this paper. A centralized computing/solving approach is assumed in this paper as opposed to distributed settings.
    \paragraph{On decoupled approaches}
	Decoupled means that paths are planned for agents seperately, which has consequences for optimality and completeness: they cannot be guaranteed. Much research has been done here: a main result is the Hierarchical cooperative A* algorithm where agents are planned one at a time and each time a path is translated to a sequence of nodes that are reserved at certain timesteps\cite{silver2005}. This can be done using a basic reservation-table that becomes increasingly full as more agents are planned. HCA* is not guaranteed to be complete (deadlocks might occur!) and found solutions are often suboptimal. It uses the admissible heuristic for each agent that is the path cost when all other agents and reservations are ignored. Other interesting idea (used for traffic modelling): flow restrictions that force agents to move in certain directions, exactly like traffic laws! Each position could be assigned one or maybe two directions.\marginnote{Really wonderful concept: think about what makes humans in cars avoid collisions, its the law!}. There are also polynomial-time decoupled algorithms based on the idea of 'macros' (pairwise swaps of agents for instance).
	
	The key take-away is that decoupled algorithms are at best complete for special types of graphs but noncomplete and almost without exception suboptimal in the general case.
	\paragraph{Coupled approaches}
	Coupled approaches take the $k$ agents to be an agent together that can be in a state that corresponds to any legal way to place $k$ agents into the $N$ vertices, with start and goal states being the entire lists given as part of the instance. 'Operators' between states are all the non-conflicting actions agents can have.
	\paragraph{Coupled approach: A*}
	With $b_{base}$ as per-agent branching factor, let $b_{potential} = b_{base}^k$ represent the worst-case potential branching factor. Let $b_{legal}$ represent the non-conflicting (and non-blocked) actions that can be taken. It turns out that in the general case, identifiying $b_{legal}$ neighbours from the $b_{potential}$ potential neighbours of a given $k$-agent state is a CSP problem with conflict-rules and map geometry as constraints (map geometry can be factored out of course by only considering non-blocked moves)
	
	With this formulation out of the way, what about heuristics (you know, what makes A* a lot nicer than UCS)? Single-agent search has many sophisticated heuristic search techniques, but state-of-the-art MAPF heuristic approaches are relatively simple. A cheap idea is summing the manhattan distance of agents to goals on grids (or air-line distance/'as the crow flies' for general graphs). Sum of individual costs assuming individual optimal paths is also possible but more expensive. Pre-calculation of all-pairs shortest path or just shortest paths from all vertices to all targets can really save work later on. Curiously, this is negligible compared to the work done for solving MAPF itself.
	
	Subgraph decmoposition can be used to abstract a map into linked structures with certain topologies like cliques, halls, rings and so on. This does not work for the general case, as in large open spaces.
	
	\paragraph{Standley's Operator decomposition for A*}
	As was mentioned before, 'operator's in this coupled scheme are the full transitions between (legal) vectors of agents. Operator decomposition\cite{standley2010} decomposes state transistions into a sequence of intermediate states where the operator is applied to an increasing number of agents (one at a time) until it is applied to all $k$ agents. The idea is to prune misleading directions that agents can go without generating all possible moves of the other agents together with such misleading directions. Graphically, if there are two agents where the first has 3 moves, the second 4, it is the difference between first considering all 3 children where you move the first agent (and stop there if the outcome is very bad after just moving this first agent) and then for each of these 3, proceed to consider all 4 children where the second agent moves versus directly considering the 12 potential children of the root.
	
	The idea here, is that usually the heuristic in A* is not only admissible but also consistent so that the estimated final cost to the goal of a partial solution $f(n)$ is monotonically non-decreasing. This means that you can get formal about the 'badness' of certain intermediate states: if their $f$ values are greater than $f_{parent}$, you can prune them because the $f$ of the select child will have $f\leq f_{parent}$ for any solution.
	\paragraph{Standley's Independence Detection for coupled MAPF generally}
	Independence detection is a top-level approach that calls your MAPF solver as subroutine. It starts by assuming that all agents are independent and plans a path for each singleton group. Then it enters a loop until no conflicts occur, that simulates execution of all paths until a conflict occurs at which point there is an optional 'band-aid' fix moment after which it will merge the conflicting groups into one and plan paths for the agents within this dependent group (that is still assumed to be independent of any other group).
	
	The worst-case of an IDified MAPF algorithm is still $O(b^k)$, but sometimes the size of the largest subproblem that has to be solved $k'$ may be smaller than $k$ so that $O(b^{k'})$ comes to dominate the complexity,meaning that you get a speedup of a factor $b^{k - k'}$ which for high $b$ and high $k$ can be a lot!
	
	This can be improved upon still using conflict avoidance (assuming A* subroutine): when solving a merged group with A*, "A* search breaks ties in favor of states that will create the least amount of conflicts with existing planned paths of other agents (agents that are not part of the merged group)". How? Maintain a table of all paths currently planned (that still have to be fully checked), and consider in particular those corresponding to agents outside the currently recomputing group: now break ties by picking the states that will conflict the lowest number of other paths. The advantage is that the independence between groups that are formed is optimized to ensure that often $k'<k$.
	
	ID is general and can be applied to any optimal MAPF solver: implementing conflict avoidance will differ per algorithm, in ICTS perhaps in the enumeration of possible path combinations you could for each agent rank the possible paths by increasing number of conflicts with agents outside of the group being merged/computed.
	\section{ICTS formalization of MAPF}
	ICTS divides MAPF into two:
	\begin{itemize}
		\item What is the cost of the path of each agent in an optimal solution?
		\item How to find a non-conflicting set of paths given individual costs?
	\end{itemize}
	This gives rise to two levels of search:
	\begin{itemize}
		\item Top-level: Search for a minimal cost combination of individual agent costs
		\item Bottom-level: Search for a valid solution given a set of cost constraints, acting as a goal-test for the top-level search.
	\end{itemize}
	\paragraph{Top-level}
	Nodes as $k$-vectors $(C_1,C_2,\ldots,C_k)$. Each node $s$ represents all possible (candidate) solutions in which the cost of each $a_i$ is $C_i$ as given by the vector, the sum being the cost of (solution) $s$. The root of the tree is given by the shortest-path costs for agents ignoring others. Successors are defined by incrementing individual agents and pruning duplicates. BFS of this structure guarantees optimality. $\Delta$ denotes the difference between the optimal cost of the complete solution and the cost of the root, so the sum of individual shortest paths. The number of ICT nodes is $O(k^\Delta)$.
	
	What about this $\Delta$ versus $k$? It is often much lower in more open settings but much higher in tight corridors with many conflicts.
	\paragraph{Bottom-level}
	A simple bottom-level check is for each agent $a_i$ to enumerate all paths of length $C_i$ and then take the cross product of all such path 'lists'. But this will be a huge cross-product!
	
	Multi-value decision diagrams give a more compact representation of all paths and also enable cheaper combination. MDDs are DAGs not unlike binary decisino diagrams but with more options. Let $MDD^c_i$ store all paths of length $c$ for $a_i$. Any $MDD^c_i$ has exactly $c$ levels (with $c\geq opt_i$) and therefore consists of $O(|V| \cdot c)$ nodes. To build an MDD, perform BFS from the start location of $a_i$ down to depth $c$ and store the resulting partial DAG starting at $start(i)$ and ending at $goal(i)$ at depth $c$. You can also reuse $MDD^c_i$ in building $MDD^{c+1}_i$. Let $MDD^c_i(x,t)$ denote a node with location $x$ at time $t$ in this diagram. 	
	\paragraph{Goal test}
	To start looking for solutions, nondeterministically (MDD must be a monadic type) combine MDDs so nodes are generated so that each possible 'choice'/action is taken by each agent at each level with conflicts being filtered out. Somewhat formally, starting at $MDD_{ij}([x_i,x_j],t)$: let $\bar x_i,\bar x_j$ be children of these roots and let $MDD_{ij}([\bar x_i,\bar x_j],t+1)$ be a child of this root if the children do not conflict. They conflict if $\bar x_i = \bar x_j$ or $\bar x_j = x_i, \bar x_i = x_j$.
	
	You could build and store $MDD_{ij}$ in memory. The sink node of a MDD is a node at which all agents arrive at their goal, found at level $c$. Intuitively you want to find a path without conflicts through the MDD to this sink. Practical MDD merging is about checking if you can get to a sink-node which indicates that there is a way to choose paths so that there is no conflicts, avoiding the full construction but instead using the formal definition of the children of a certain node (non-conflicting combinations of the children of all agents from which (sub)MDDs are 'merged') in something like a depth-first search.
	
	For $k > 2$ agents, the constructive definition in any case is boring and inductive/recursive. The definitional one is also not too bad: a node $n = MDD_{[k]}(x[k],t)$ in a $k$-agent MDD has $k$ locations of $k$ agents at time $t$ in the vector $x_[k]$. It is the unification  of $k$ single-agent MDD nodes of level $t$ that do not conflict. The size of $MDD_{[k]}$ is $O(c \times |V| ^k)$ so exponential in $k$. This is why in practice you only want to build the actual MDDs for individual agents and use the above definition for nodes in the $k$-agent MDD in a search. Note: worst-case is that there is no way to a node at level $c$ which in practice means that a large chunk of the exponential tree will have to be visited. If conflicts occur early this might make up for this. 
	
	How to search? Just be systematic and exhaustive. DFS is nice because it is usually 'the fastest way down' and the goal is to get to the node with depth $c$.
	
	Consider the use of ID. If it is not used, you could just do DFS (formally best-first search expanding the highest $g(n)$ node $n$) with maybe a transposition table to avoid visiting nodes twice. If ID is used, maintain a conflict avoidance table with the possibly conflicting (space,time) nodes of other groups as before and do best-first search preferring nodes with the fewest conflicts with other groups (maybe as tie-breaker in a similar BFS formulation)?
	
	\paragraph{Analysis: ICTS versus A* with OD using SIC heuristic}
	A* expands all nodes with f < C* and some of the nodes with f = C*. The worst-case is expanding all $n$ with $f(n) \leq C*$ assuming in this case the SIC heuristic. Denote the number of such nodes with $X$. A* with a consistent heuristic (like SIC) by \cite{dechter1985} is optimally effective/efficient meaning that it expands the minimal number of nodes to get get an admissible solution. \marginnote{In Dechter's paper, tie-breaking also plays a role in the result statement}. So any admissible MAPF algorithm is at least $O(X)$. It turns out that A* (with OD) does much worse than this in practice.
	
	Understanding ICTS complexity has two parts: first the complexity of individual per-node bottom-level searches, next how these are composed as part of top-level traversal of the ICT. $O(k^\Delta)$ ICT nodes are visited in the top-level. Such a visit involves constructing $k$ single-agent MDDs with costs depending on the ICT node and next searching the k-agent MDD search space. The first part is crudely $O(k\cdot c_{max} \cdot |V|)$ where $c_{max}$ is the maximal cost of any agent in the node, so it can be omitted as the complexity of searching the MDD search space is higher and bounded by $X$:
	
	Firstly, for any node $m$ visited in this $k$-agent search space for node $(C_1,\ldots,C_k)$, $f(m) \leq \sum_{i=1}^k C_i$ with SIC being the heuristic in $f$. Outline of the proof: $m$ is a possible configuration of agents at a time-step, consisting of $loc_i(m)$ for each agent $a_i$. Let $g_i(m)$ denote the cost of $a_i$ arriving there, $h_i(m)$ the (admissible) estiamte of the distance from $loc_i(m)$ to $goal_i$ and $f_i(m) = g_i(m) + h_i(m)$. Clearly
	\[f(m) = g(m) + h(m) = \sum_{i=1}^k g_i(m) + \sum_{i=1}^k h_i(m) = \sum_{i=1}^kf_i(m)\]
	Following the MDD construction, each $MDD_i$ contains nodes on a path of cost $C_i$ from $start_i$ to $goal_i$ so $f_i(m) \leq C_i$ (as $f_f(m)$ uses admissible heuristic $h_i(m)$). This then means that always $f(m) \leq \sum_{i=1}^kC_i$
	
	Now by definition of the ICT traversal, at any point $\sum_{i = 1}^k C_i \leq C*$. So together, for any node $m$ visited in low-level search,  $f(m) \leq C*$. So at most $X$ states are visited in a low-level search and the transposition table makes sure that states are visited at most once. 
	
	Note: $n$ with $f(n) > C*$ are never considered, not even to reject them!
	\paragraph{A* analysis}
	A* expands only X nodes but generates many more as all $b_{legal} = O(b_{base}^k)$ children are generated in expansion so that A* generates $O(X \times b_{legal}$ nodes in fact. Because 'visiting' in A* is constant, you might as well say that as far as complexity is concerned $O(X \times b_{legal}$ nodes are visited. OD changes the branching factor from $b_{legal}$ to $b_{base}$ but increases the depth of the goal node by a factor $k$. Some analysis suggests therefore $\Omega(X \times b_{base})$ as a lower bound for complexity. Worst-case? Consider agent $a_i$ at $loc$ with $h_{SIC}$ being the heuristic and $b_{SIC}$ the number of neighbours with $h_{SIC} = h_{SIC}(loc) - 1$ (at most two in diagonal case on 4-grid). In A* OD, at worst $b_{SIC}$ out of $b_{base}$ will be expanded as they have the same $f$ as the parent. So $O(b_{SIC}^k)$ intermediate nodes will be expanded under a given full node and each of these will also generate $b_{base}-b_{SIC}$ children that are not expanded. So the number of generated nodes is $O(b_{SIC}^k(b_{base}-b_{SIC})) \equiv O(b_{SIC}^k)$. The result is as expected: still an exponential number of nodes is generated but the base of the exponential is rather different, which is rather important in practical complexity. Now this $O(b_{SIC}^k)$ thing is only a single node generating children, so in the end the complexity is $O(X\times b_{SIC}^k)$ because you do it for every node you minimally have to expand for optimality.
	
	On a 4-grid: the factor changes from $5^k$ to $2^k$.
	
	\paragraph{Analysis summarized}
	Remembering that $b_{base} = 5$, $b_{SIC} = 2$ (both worst-case values),
	Basic A* is $O(X\times b^k_{base}$, A* with OD is $O(X\times b_{IC}^k\cdot b_{base})$ and ICTS is $O(X\times k^\Delta)$. So what is interesting in benchmarks and practical scenarios is knowing when $\Delta$ be large or small. There is no easy answer here, but it will usually be high in dense, high $k$ scenarios and low in more open low $k$ scenarios.
	
	\paragraph{Experimental results}
	Let $k'$ denote the effective number of agents, the size of the largest subproblem solved by embedding algorithms in the ID framework.
	
	Type 1: both using ID. Uniformly random locations, $k$ agents, average $k'$ is reported.
	
	Type 2: Not using ID, so always $k' = k$, fixed number of agents with no ID tricks. ID is used to 'fill buckets' with problem instances of these fixed number of agents however by randomly simulating IDified MAPF until each $k$ value has enough samples. Because they are generated by ID, there is at least one agent always that conflicts with others so that they really are a dependent (coupled) group of agents.
	
	Nodes reported for A* are just full nodes and in OD also intermediate nodes. In ICTS, it is the sum of $k$-agent MDD nodes visited in the low-level searches.
	
	experimental result: $\Delta$ gets high for many conflicts. The relation between $k$ and the number of conflicts is complicated: the density $k/N$ with $|V| = N$ being the number of nodes is relevant but does not tell all, map topology is important to.
	
	The 50ms for A*, 37 seconds for ICTS example is curious: it is a pathology caused by topology not by something crude like density.
	
	ICTS with makespan: linearly increasing ICT, integer division enumeration at each node.
	\paragraph{Pruning for ICTS}
	Only the last node is a goal node for which the goal test will return true. Before fully doing low-level search, can we perhaps try to prune a node? You could pairwise search each $MDD_{ij}$ with DFS for a solution for every possible pair. If there is none for any pair, you know you can prune. This approach is called simple pairwise pruning. It results in $k \choose 2$ runs of 2-agent-MDD search.
	
	Enhanced pairwise pruning: in enhanced pairwise pruning, you do breadth-first search in the pairwise pruning and modify the MDDs of agents as you go: specifically, you remove any conflicting nodes, nodes that cannot be added when combining the two. This is called unfolding in the paper. The result of this is that more often there will be a possibility to prune (called cascading effect) and once you get to bottom-level search if no pruning is done, the work is much lighter.
	
	This cascading effect is curious in that if you would start looping over all pairs from the beginning, you may still prune the node. This is essentially the repeated enhanced pruning technique, which will either result in a prune or stop iterating when agent MDDs stop changing. This is like arc-consistency in CSP.
	
	SPP versus (iterated) EPP: EEP's BFS can be much slower than SPP's DFS, but EEP may result in more prunes and less work if pruning doesn't work (so time is not just wasted if in the end there is no prune). In terms of complexity, even in DFS the worst case is that all $|V|^2\times d$ nodes of the two-agent MDD of depth $d$ are visited which is done for all $k \choose 2$ pairs so both SPP and EPP are $O(|V|^2\times k^2)$
	
	All the above can be applied to $m$-agents. $m=3$ is often a good value. Emperically, repeated enhanced variants seem just not worth it. The difference between enhanced and simple is already very large. 
	
	Conclusion from emperical comparison: enhanced pruning becomes important on dense, complicated graphs with many agents. More generally, you need to prune like crazy if there's a lot of agents on a small map.
	
	Another conclusion: ICTS with ID and 3 enhanced pruning is a powerful combination, it can solve problems fast!
	
	Immediate expand enhancement for A*: if child node has exact same $f$ value, immediately expand the thing.
	
	\paragraph{Discussion and future work}
	ICTS was presented, compared to state-of-the-art A* approach with OD, ID, immediate expand and so on. A* degrades as k increases, ICTS performance degrades as $\Delta$ increases (function of both $k$ and map size).
	
	Generally: if $\Delta$ is expected to be high due to dense map, high $k$, go for more sophisticated pruning.
	
	Future work directions: low-level search as just a constraint satisfaction problem: use of general CSP methods, more advanced pruning. Development of current arc-consistency and path-consistency ideas encoded in algorithm.
	
	Understanding problem (instance) parameters and relation to ICTS (and pruning) performance.
	
	ICTS for weighted graphs, agents with abstract goal instead of specific goal (group of agents should leave certain area... why does this sound military somehow?)
	\printbibliography
	
\end{document}
